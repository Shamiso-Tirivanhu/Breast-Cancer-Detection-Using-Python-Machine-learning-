#  Breast-Cancer-Detection using Python & Machine Learning-project

Table of Content
1. [Overview](#overview)
2. [Features](#features)
3. [Technological Uses](#technologuical-uses)
4. [Results](#ewsults)
5. [Conclusion](#conclusion)

## 1. Overview

This project focuses on leveraging machine learning techniques to classify breast cancer cases as malignant or benign based on medical data. The goal is to provide a reliable and efficient way to assist in early diagnosis using Logistic Regression, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Decision Trees.

## 2. Features

- Data preprocessing & visualization
- Feature scaling & correlation analysis
- Multiple ML models for classification
- Performance evaluation using accuracy, confusion matrix & classification report

## 3. Technological Used

- Python
- Pandas & Numpy for Data Manipulation
- Matplotlib & Seaborn for Data visualization
- Sckit-Learn for Machine Learning algirthms 

## 3. Usage

1. Koad the dataset Breast_cancer_csv
2. Preprocessing and Data Visualization
3. Train models and evaluate their performance

## 4. Results

| Model | Accuracy | Key Insights
--------|----------|--------------|
| Logistic Regression | 95% | Relaible & interpretable minimal false positives |
| KNN | 95% | Sensitive to neigbour selection, competitive results |
| SVM | 95% | Best performer, excellent class separation |
| Decision Tree | 88% | Prone to overfitting , lower accuracy |

## 5. Conclusion 

- Logistic Regression (96%): Performed well with high accuracy and minimal false positives, making it a reliable choice for interpretability.
- K-Nearest Neighbors (95%): Showed competitive performance but is sensitive to the choice of neighbors, which may affect predictions.
- Support Vector Machine (97%): Outperformed other models by efficiently separating classes, making it the best performer in this study.
- Decision Tree (88%): Provided interpretability but had lower accuracy, likely due to overfitting on the training data.

- Among all models, SVM proved to be the most effective, achieving the highest accuracy at 97%. However, further improvements can be explored using ensemble methods or deep learning techniques for even better performance.

ðŸ’¡ Check out the code and feel free to contribute ðŸ›¶


